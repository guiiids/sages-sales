# ============================================
# AZURE OPENAI CONFIGURATION
# ============================================

# AZURE_OPENAI_ENDPOINT: Azure OpenAI service endpoint URL
# Required: Yes
AZURE_OPENAI_ENDPOINT=https://support02.openai.azure.com/

# AZURE_OPENAI_API_KEY: Authentication key for Azure OpenAI (primary deployment)
# Required: Yes
AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
# AZURE_OPENAI_KEY: Alternative/legacy key name for Azure OpenAI
# Note: Use AZURE_OPENAI_API_KEY for consistency
AZURE_OPENAI_KEY=your-azure-openai-key-here

# AZURE_OPENAI_API_VERSION: API version to use for standard deployments
# Options:
#   - 2024-08-01-preview: Standard API version with latest features
#   - 2024-12-01-preview: Newer preview with additional capabilities
# Default: 2024-08-01-preview
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME: Deployment name for chat completions
# Default: deployment03
AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME=deployment03

# AZURE_OPENAI_MODEL: Model name/identifier for primary chat deployment
# Options:
#   - gpt-4o-prod: GPT-4 Optimized for production
#   - gpt-4o: Standard GPT-4 Optimized
#   - gpt-35-turbo: GPT-3.5 Turbo (faster, lower cost)
# Default: gpt-4o-prod
AZURE_OPENAI_MODEL=gpt-5.2-local

# AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME: Deployment name for embeddings
# Default: text-embedding-3-small
AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME=text-embedding-3-small

# EMBEDDING_DEPLOYMENT: Alternative name for embeddings deployment
# Default: text-embedding-3-small-prod
EMBEDDING_DEPLOYMENT=text-embedding-3-small-prod

# AZURE_OPENAI_DEPLOYMENT: Legacy deployment name for Azure OpenAI
# Note: Prefer AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME for new code
# Default: gpt-35-turbo
AZURE_OPENAI_DEPLOYMENT=gpt-35-turbo

# AZURE_OPENAI_EMBEDDING_NAME: Legacy name for embeddings deployment
# Note: Prefer AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME for new code
AZURE_OPENAI_EMBEDDING_NAME=text-embedding-3-small

# CHAT_DEPLOYMENT: Primary chat model deployment name
# Note: Used in rag_assistant.py and config.py as main chat deployment
# Default: gpt-4o-prod
CHAT_DEPLOYMENT=gpt-5.2-local

# OPENAI_ENDPOINT: Legacy alias for Azure OpenAI endpoint
# Note: Use AZURE_OPENAI_ENDPOINT for consistency
OPENAI_ENDPOINT=https://support02.openai.azure.com/

# OPENAI_KEY: Legacy alias for Azure OpenAI API key
# Note: Use AZURE_OPENAI_API_KEY for consistency
OPENAI_KEY=your-openai-key-here

# OPENAI_API_VERSION: Legacy alias for API version
# Note: Use AZURE_OPENAI_API_VERSION for consistency
# Default: 2024-08-01-preview
OPENAI_API_VERSION=2024-08-01-preview

# SEARCH_ENDPOINT: Legacy alias for Azure Search endpoint
# Note: Use AZURE_SEARCH_SERVICE for consistency
SEARCH_ENDPOINT=https://capozzol01searchservice.search.windows.net

# SEARCH_INDEX: Legacy alias for Azure Search index name
# Note: Use AZURE_SEARCH_INDEX for consistency
SEARCH_INDEX=vector-rag-1759761254744-pool-17-synonyms-indexer

# SEARCH_KEY: Legacy alias for Azure Search key
# Note: Use AZURE_SEARCH_KEY for consistency
SEARCH_KEY=your-search-key-here

# ============================================
# AZURE OPENAI - GPT-5 CONFIGURATION
# ============================================

# AZURE_OPENAI_ENDPOINT_GPT_5: Endpoint for GPT-5 deployment
# Note: Only required if using GPT-5 model
AZURE_OPENAI_ENDPOINT_GPT_5=https://support02.openai.azure.com/

# AZURE_OPENAI_API_KEY_GPT_5: Dedicated API key for GPT-5 access
# Note: May be same as main key or separate for GPT-5 specific deployment
AZURE_OPENAI_API_KEY_GPT_5=your-azure-openai-api-key-gpt-5-here

# AZURE_OPENAI_API_VERSION_GPT_5: API version for GPT-5 models
# Default: 2025-01-01-preview
# Note: GPT-5 may require newer API versions
AZURE_OPENAI_API_VERSION_GPT_5=2025-01-01-preview

# AZURE_OPENAI_MODEL_GPT_5: GPT-5 model deployment name
# Default: gpt-4o-prod
AZURE_OPENAI_MODEL_GPT_5=gpt-5.2-local

# CHAT_DEPLOYMENT_GPT_5: Chat completion deployment for GPT-5
# Default: gpt-4o-prod
CHAT_DEPLOYMENT_GPT_5=gpt-5.2-local

# ============================================
# AZURE OPENAI - O4-MINI CONFIGURATION
# ============================================

# AZURE_OPENAI_API_VERSION_O4_MINI: API version for O4-Mini model
# Default: 2024-12-01-preview
AZURE_OPENAI_API_VERSION_O4_MINI=2024-12-01-preview

# CHAT_DEPLOYMENT_O4_MINI: Deployment name for O4-Mini chat model
# Default: deployment03
# Note: O4-Mini is a smaller, faster model variant
CHAT_DEPLOYMENT_O4_MINI=deployment03

# CHAT_DEPLOYMENT_GPT4o: Standard GPT-4o chat deployment
# Default: gpt-4o-prod
CHAT_DEPLOYMENT_GPT4o=gpt-4o-local

# ============================================
# AZURE OPENAI - TRANSCRIPTION
# ============================================

# AZURE_OPENAI_ENDPOINT_TRANSCRIPTION: Full endpoint URL for audio transcription
# Note: Includes deployment path and API version
# Example: https://your-resource.openai.azure.com/openai/deployments/gpt-4o-transcribe/audio/transcriptions?api-version=2025-03-01-preview
AZURE_OPENAI_ENDPOINT_TRANSCRIPTION=https://support02.openai.azure.com/openai/deployments/gpt-4o-transcribe/audio/transcriptions?api-version=2025-03-01-preview

# AZURE_OPENAI_KEY_TRANSCRIPTION: API key for transcription service
# Note: May be separate from main API key depending on security setup
AZURE_OPENAI_KEY_TRANSCRIPTION=your-azure-openai-key-transcription-here

# ============================================
# COST TRACKING
# ============================================

# DEPLOYMENT02_PROMPT_COST_PER_1K: Cost per 1,000 prompt tokens for deployment02
# Default: 2.50 (USD)
# Note: Update based on current Azure pricing
DEPLOYMENT02_PROMPT_COST_PER_1K=2.50

# DEPLOYMENT02_COMPLETION_COST_PER_1K: Cost per 1,000 completion tokens for deployment02
# Default: 10.00 (USD)
# Note: Update based on current Azure pricing
DEPLOYMENT02_COMPLETION_COST_PER_1K=10.00

# O4_MINI_PROMPT_COST_PER_1K: Cost per 1,000 prompt tokens for O4-Mini
# Default: 1.10 (USD)
# Note: O4-Mini is more cost-effective than standard models
O4_MINI_PROMPT_COST_PER_1K=1.10

# O4_MINI_COMPLETION_COST_PER_1K: Cost per 1,000 completion tokens for O4-Mini
# Default: 4.40 (USD)
O4_MINI_COMPLETION_COST_PER_1K=4.40

# OPENAI_COST_PER_INPUT_TOKEN: Cost per single input token for DeepEval metrics calculation
# Example: 0.00000125 ($1.25 per 1M tokens) for GPT-5 models
# Note: Used in the evaluation framework to calculate total run costs
OPENAI_COST_PER_INPUT_TOKEN=your-openai-cost-per-input-token-here

# OPENAI_COST_PER_OUTPUT_TOKEN: Cost per single output token for DeepEval metrics calculation
# Example: 0.00001 ($10.00 per 1M tokens) for GPT-5 models
# Note: Used for expenditure reporting in validation reports
OPENAI_COST_PER_OUTPUT_TOKEN=your-openai-cost-per-output-token-here

# ============================================
# AZURE AI SEARCH CONFIGURATION
# ============================================

# AZURE_SEARCH_SERVICE: Azure AI Search service endpoint URL
# Required: Yes
AZURE_SEARCH_SERVICE=https://capozzol01searchservice.search.windows.net

# AZURE_SEARCH_KEY: Query key for Azure AI Search
# Required: Yes
# Note: Use query key for read operations, admin key only if needed
AZURE_SEARCH_KEY=your-azure-search-key-here

# AZURE_SEARCH_ADMIN_KEY: Admin key for Azure AI Search (management operations)
# Required: Only for index creation/modification
# Note: Keep separate from query key for security
AZURE_SEARCH_ADMIN_KEY=your-azure-search-admin-key-here

# AZURE_SEARCH_INDEX: Name of the search index to query
# Default: vector-rag-index
# Example: vector-rag-1759761254744-pool-17-synonyms-indexer
AZURE_SEARCH_INDEX=vector-rag-1759761254744-pool-17-synonyms-indexer

# DATASOURCE_TYPE: Type of data source backend
# Options:
#   - AzureCognitiveSearch: Azure AI Search (recommended)
#   - Other: Alternative data source implementations
# Default: AzureCognitiveSearch
DATASOURCE_TYPE=AzureCognitiveSearch

# SEARCH_TOP: Maximum number of search results to retrieve
# Default: 100
# Impact: Higher values provide more candidates for reranking but increase latency
SEARCH_TOP=100

# SEARCH_KNN: Number of nearest neighbors for vector search (k-NN)
# Default: 50
# Impact: Higher values improve recall but increase computational cost
SEARCH_KNN=50

# VECTOR_FIELD: Name of the vector field in the search index
# Default: text_vector
# Note: Must match the field name in your search index schema
VECTOR_FIELD=text_vector

# SEARCH_TITLE_FIELDS: Comma-separated list of fields to search for document titles
# Default: title,name,metadata_storage_name,document_title
# Note: Used to extract meaningful document identifiers
SEARCH_TITLE_FIELDS=title,name,metadata_storage_name,document_title

# SEARCH_DEFAULT_TITLE: Default title when no title field is found
# Default: "Untitled Document"
SEARCH_DEFAULT_TITLE="Untitled Document"

# ============================================
# AZURE STORAGE CONFIGURATION
# ============================================

# AZURE_STORAGE_ACCOUNT_NAME: Azure Storage account name
# Required: If using Azure Blob Storage for documents
AZURE_STORAGE_ACCOUNT_NAME=capozzol02storage

# AZURE_STORAGE_ACCOUNT_KEY: Azure Storage account access key
# Required: If using Azure Blob Storage
AZURE_STORAGE_ACCOUNT_KEY=your-azure-storage-account-key-here

# AZURE_STORAGE_CONNECTION_STRING: Full connection string for Azure Storage
# Note: Alternative to using account name + key separately
# Format: DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net
AZURE_STORAGE_CONNECTION_STRING=your-azure-storage-connection-string-here

# ============================================
# AZURE LANGUAGE SERVICE
# ============================================

# AZURE_LANGUAGE_SERVICE_ENDPOINT: Azure Language Service endpoint
# Note: Used for NLP features like entity extraction, sentiment analysis
AZURE_LANGUAGE_SERVICE_ENDPOINT=https://gui-langser.cognitiveservices.azure.com/

# AZURE_LANGUAGE_SERVICE_KEY: API key for Azure Language Service
AZURE_LANGUAGE_SERVICE_KEY=your-azure-language-service-key-here

# ============================================
# AZURE APPLICATION INSIGHTS
# ============================================

# AZURE_APPINSIGHTS_CONNECTION_STRING: Application Insights connection string for telemetry
# Format: InstrumentationKey=...;IngestionEndpoint=...;LiveEndpoint=...;ApplicationId=...
# Note: Used for application monitoring, performance tracking, and diagnostics
AZURE_APPINSIGHTS_CONNECTION_STRING=your-azure-appinsights-connection-string-here

# ENABLE_RERANKER: Master switch to enable/disable reranking entirely
# Options:
#   - true: Enables reranking with the configured mode
#   - false: Returns search results in original order
# Default: false
ENABLE_RERANKER=false

# RERANKER_MODE: Controls how search results are reranked to improve relevance
# Options:
#   - cosine: Uses cosine similarity scoring only (fastest, baseline performance)
#   - llm: Uses LLM-based semantic scoring (slowest, highest quality)
#   - hybrid: Combines cosine similarity with LLM scoring for close matches (balanced)
# Default: cosine
# Impact: LLM and hybrid modes add 200-500ms latency but improve result quality
RERANKER_MODE=

# RERANKER_TOP_N: Number of top search results to rerank
# Default: 10
# Impact: Higher values improve thoroughness but increase latency
RERANKER_TOP_N=10


# ============================================
# COHERE RERANKER (AZURE AI FOUNDRY)
# ============================================

# USE_COHERE_RERANKER: Enable Cohere's neural reranking model via Azure
# Options:
#   - True: Uses Cohere rerank model for semantic reranking (high quality)
#   - False: Uses built-in reranking (cosine/LLM/hybrid modes above)
# Default: False
# Impact: Cohere reranker provides state-of-the-art reranking but adds API latency
USE_COHERE_RERANKER=False

# COHERE_AZURE_ENDPOINT: Azure AI Foundry endpoint for Cohere service
# Required: If USE_COHERE_RERANKER=True
# Example: https://your-resource.cognitiveservices.azure.com
COHERE_AZURE_ENDPOINT=https://guilh-m7uwrx85-eastus2.cognitiveservices.azure.com

# COHERE_AZURE_DEPLOYMENT: Cohere model deployment name
# Options:
#   - Cohere-rerank-v4.0-pro: Latest professional reranking model (recommended)
#   - Cohere-rerank-v3.5: Previous generation model
# Default: Cohere-rerank-v4.0-pro
COHERE_AZURE_DEPLOYMENT=Cohere-rerank-v4.0-pro

# COHERE_AZURE_API_VERSION: API version for Cohere on Azure
# Default: 2024-05-01-preview
COHERE_AZURE_API_VERSION=2024-05-01-preview

# COHERE_AZURE_API_KEY: API key for Cohere service on Azure
# Required: If USE_COHERE_RERANKER=True
COHERE_AZURE_API_KEY=your-cohere-azure-api-key-here

# COHERE_RERANK_TOP_N: Number of results to return after Cohere reranking
# Default: 5
# Impact: Lower values return only the most relevant results
COHERE_RERANK_TOP_N=5

# ============================================
# QUERY ENHANCEMENT
# ============================================

# ENABLE_QUERY_ENHANCEMENT: Enhances user queries before search
# Options:
#   - true: Enables query expansion, synonym replacement, and clarification
#   - false: Uses user queries as-is
# Default: false
# Impact: Adds ~100-300ms latency but improves retrieval accuracy
ENABLE_QUERY_ENHANCEMENT=false

# ============================================
# LOGGING CONFIGURATION
# ============================================

# LOG_LEVEL: Controls verbosity of application logging
# Options:
#   - DEBUG: All logs including debug information (verbose)
#   - INFO: General informational messages (recommended for production)
#   - WARNING: Warning messages and errors only
#   - ERROR: Error messages only (minimal logging)
# Default: INFO
LOG_LEVEL=INFO

# LOG_FILE: Path to the application log file
# Default: app.log
# Note: Relative to application root directory
LOG_FILE=app.log

# LOG_FORMAT: Format string for log messages
# Default: "%(asctime)s - %(levelname)s - %(message)s"
# Note: Python logging format string
LOG_FORMAT="%(asctime)s - %(levelname)s - %(message)s"

# ENABLE_OPERATIONAL_LOGGING: Logs all queries and responses to Cosmos DB
# Options:
#   - true: Enables comprehensive operational logging
#   - false: Disables operational logging (minimal logs)
# Default: true
# Impact: Required for analytics dashboard and feedback tracking
ENABLE_OPERATIONAL_LOGGING=true

# ============================================
# REDIS CACHE CONFIGURATION
# ============================================

# REDIS_HOST: Redis server hostname
# Default: localhost
# Note: Use Azure Cache for Redis hostname in production
REDIS_HOST=localhost

# REDIS_PORT: Redis server port
# Default: 6379
REDIS_PORT=6379

# REDIS_SSL: Enable SSL/TLS for Redis connection
# Options:
#   - True: Use SSL (required for Azure Cache for Redis)
#   - False: No SSL (local development only)
# Default: False
REDIS_SSL=False

# REDIS_CACHE_EXPIRATION: Cache expiration time in seconds
# Default: 3600 (1 hour)
# Impact: Longer expiration reduces API calls but may serve stale data
REDIS_CACHE_EXPIRATION=3600

# ============================================
# DATABASE CONFIGURATION - COSMOS DB
# ============================================

# COSMOS_URI: Azure Cosmos DB endpoint for logging and chat memory
# Required: If ENABLE_OPERATIONAL_LOGGING=true or using chat memory
# Format: https://your-cosmos-account.documents.azure.com:443/
COSMOS_URI=https://ragka-cosmos-db.documents.azure.com:443/

# COSMOS_KEY: Master key for Cosmos DB access
# Required: If using Cosmos DB
COSMOS_KEY=your-cosmos-key-here

# COSMOS_DB: Cosmos DB database name
# Default: rag
COSMOS_DB=rag

# COSMOS_CONTAINER: Cosmos DB container for chat memory/conversations
# Default: chat_memory
COSMOS_CONTAINER=chat_memory

# ============================================
# DATABASE CONFIGURATION - POSTGRESQL
# ============================================

# POSTGRES_HOST: PostgreSQL server hostname
# Example: your-server.postgres.database.azure.com
POSTGRES_HOST=ragka-v1r1-server.postgres.database.azure.com

# POSTGRES_PORT: PostgreSQL server port
# Default: 5432
POSTGRES_PORT=5432

# POSTGRES_DB: PostgreSQL database name
# Default: postgres
POSTGRES_DB=postgres

# POSTGRES_USER: PostgreSQL username
# Required: Yes
POSTGRES_USER=pioneercrew

# POSTGRES_PASSWORD: PostgreSQL user password
# Required: Yes
POSTGRES_PASSWORD=your-postgres-password-here

# POSTGRES_SSL_MODE: SSL mode for PostgreSQL connection
# Options:
#   - require: Requires SSL connection (recommended for Azure PostgreSQL)
#   - prefer: Attempts SSL, falls back to non-SSL
#   - disable: No SSL (not recommended for production)
# Default: require
POSTGRES_SSL_MODE=require

# PGHOST: PostgreSQL host (libpq fallback)
# Note: Falls back from POSTGRES_HOST, used by some PostgreSQL clients
# Default: localhost
PGHOST=localhost

# PGPORT: PostgreSQL port (libpq fallback)
# Note: Falls back from POSTGRES_PORT
# Default: 5432
PGPORT=5432

# PGDATABASE: PostgreSQL database (libpq fallback)
# Note: Falls back from POSTGRES_DB
# Default: postgres
PGDATABASE=postgres

# PGUSER: PostgreSQL user (libpq fallback)
# Note: Falls back from POSTGRES_USER
# Default: postgres
PGUSER=postgres

# PGPASSWORD: PostgreSQL password (libpq fallback)
# Note: Falls back from POSTGRES_PASSWORD
PGPASSWORD=your-pgpassword-here

# PGSSLMODE: PostgreSQL SSL mode (libpq fallback)
# Note: Falls back from POSTGRES_SSL_MODE
# Default: require
PGSSLMODE=require

# ============================================
# PERFORMANCE TUNING
# ============================================

# SEARCH_TIMEOUT_MS: Maximum time to wait for search results in milliseconds
# Default: 5000 (5 seconds)
# Impact: Lower values fail faster but may miss results; higher values are more resilient
SEARCH_TIMEOUT_MS=5000

# MAX_TOKENS: Maximum tokens for LLM response
# Default: 1500
# Impact: Higher values allow longer responses but increase cost and latency
MAX_TOKENS=your-max-tokens-here

# TEMPERATURE: Controls randomness in LLM responses (0.0 to 2.0)
# Default: 0.7
# Impact: Lower = more focused/deterministic, Higher = more creative/random
TEMPERATURE=0.7

# ============================================
# FEATURE FLAGS
# ============================================

# ENABLE_CONVERSATION_HISTORY: Maintains chat history for context
# Options:
#   - true: Enables multi-turn conversations with memory
#   - false: Each query is treated independently
# Default: true
ENABLE_CONVERSATION_HISTORY=true

# ENABLE_CLARIFIER: Asks clarifying questions for ambiguous queries
# Options:
#   - true: AI may ask follow-up questions before answering
#   - false: AI provides best-effort answer immediately
# Default: false
# Impact: Improves accuracy for vague queries but requires additional user interaction
ENABLE_CLARIFIER=false

# CONFIG_CHECK_STRICT: Fail startup on critical config mismatches
# Options:
#   - true: Fail startup if env values are ignored/overridden
#   - false: Log warnings only (default)
# Default: false
# Impact: Enforces config consistency in production environments
CONFIG_CHECK_STRICT=false

# SHOW_VERSION_BANNER: Toggles the version banner on the frontend
# Options:
#   - true: Show the banner
#   - false: Hide the banner
# Default: false
SHOW_VERSION_BANNER=false

# ENABLE_EXPERIMENTAL_MODE_TOGGLE: Shows/hides the Sage Experimental Mode toggle in the UI
# Options:
#   - true: Show the toggle switch in the header (allows users to switch modes)
#   - false: Hide the toggle (production default, users only see production mode)
# Default: false
# Note: When enabled, users can switch between Production and Experimental modes.
#       In Experimental mode, settings prefixed with EXP_ are used instead.
#       Example: EXP_AZURE_OPENAI_MODEL=gpt-5.2-local overrides AZURE_OPENAI_MODEL
ENABLE_EXPERIMENTAL_MODE_TOGGLE=false

# ENABLE_STREAMING: Enables streaming response mode for the chat interface
# Options:
#   - true: The frontend will use the /api/stream_query endpoint and render responses incrementally.
#   - false: The frontend will use the /api/query endpoint and render the full response at once.
# Default: false
ENABLE_STREAMING=false

# ============================================
# APPLICATION SETTINGS
# ============================================

# FLASK_ENV: Flask environment mode
# Options:
#   - development: Debug mode enabled, hot reload
#   - production: Optimized for production deployment
# Default: production
FLASK_ENV=production

# FLASK_DEBUG: Enable Flask debug mode
# Options:
#   - True: Enable debug mode (development only)
#   - False: Disable debug mode (production)
# Default: False
FLASK_DEBUG=False

# PORT: Port number for Flask application
# Default: 5001
PORT=5001

# ALLOWED_ORIGINS: CORS allowed origins (comma-separated)
# Default: * (all origins - not recommended for production)
# Example: https://yourdomain.com,https://app.yourdomain.com
ALLOWED_ORIGINS=*

# FEEDBACK_DIR: Directory for storing user feedback data
# Default: feedback_data
# Note: Used for collecting and analyzing user feedback
FEEDBACK_DIR=feedback_data

# FEEDBACK_FILE: Filename for storing feedback data
# Default: feedback.json
FEEDBACK_FILE=feedback.json

# FLASK_SECRET_KEY: Secret key for Flask session management
# Required: Yes (for session security)
# Note: Generate a secure random key for production
FLASK_SECRET_KEY=your-flask-secret-key-here

# CONFIG_DEBUG_TOKEN: Access token for /config debug endpoint
# Required: Yes (for troubleshooting environment config)
# Note: Keep secret! Do not expose in client-side code.
CONFIG_DEBUG_TOKEN=your-secret-token-here

# LOG_BASE: Base directory for log files
# Default: logs
LOG_BASE=logs

# SAS_TOKEN: Azure Blob Storage SAS token for document access
# Note: Used for generating secure links to blob storage resources
SAS_TOKEN=your-sas-token-here

# GROUNDEDNESS_TEMPERATURE: Temperature for groundedness checking (factual accuracy)
# Default: 0.0
# Impact: 0.0 = deterministic, higher = more variation (keep at 0.0 for consistency)
GROUNDEDNESS_TEMPERATURE=0.0

# ============================================
# DOCKER & DEPLOYMENT
# ============================================

# DOCKER_REGISTRY_SERVER_URL: Docker registry URL for deployment
# Default: https://index.docker.io
# Note: Change if using Azure Container Registry or private registry
DOCKER_REGISTRY_SERVER_URL=https://index.docker.io

# WEBSITES_ENABLE_APP_SERVICE_STORAGE: Azure Web App storage setting
# Options:
#   - true: Enable persistent storage in Azure Web App
#   - false: Use ephemeral storage (recommended for stateless apps)
# Default: false
WEBSITES_ENABLE_APP_SERVICE_STORAGE=false

# ============================================
# TESTING CONFIGURATION
# ============================================

# DISABLE_REAL_TESTS: Skip tests that require real API connections
# Options:
#   - true: Skip integration tests (useful for CI without API access)
#   - false: Run all tests including real API calls
# Default: false
DISABLE_REAL_TESTS=false

# OPENAI_API_KEY: OpenAI API key for tests that use direct OpenAI
# Note: Only required for specific integration tests
OPENAI_API_KEY=your-openai-api-key-here
